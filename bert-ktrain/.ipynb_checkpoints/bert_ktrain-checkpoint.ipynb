{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following notebook uses the Keras wrapper library ktrain to build a BERT classifier \n",
    "\n",
    "ktrain : \n",
    "@article{maiya2020ktrain,\n",
    "         title={ktrain: A Low-Code Library for Augmented Machine Learning},\n",
    "         author={Arun S. Maiya},\n",
    "         journal={arXiv},\n",
    "         year={2020},\n",
    "         volume={arXiv:2004.10703 [cs.LG]}\n",
    "}\n",
    "\n",
    "BERT : https://arxiv.org/abs/1810.04805\n",
    "\n",
    "Keras : \n",
    "@misc{chollet2015keras,\n",
    "  title={Keras},\n",
    "  author={Chollet, Fran\\c{c}ois and others},\n",
    "  year={2015},\n",
    "  howpublished={\\url{https://keras.io}},\n",
    "}\n",
    "\n",
    "Sklearn (used only for train-test split): \n",
    "@article{scikit-learn,\n",
    " title={Scikit-learn: Machine Learning in {P}ython},\n",
    " author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.\n",
    "         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.\n",
    "         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and\n",
    "         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},\n",
    " journal={Journal of Machine Learning Research},\n",
    " volume={12},\n",
    " pages={2825--2830},\n",
    " year={2011}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### requirements :  \n",
    "pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NSkAD3xS2qfT"
   },
   "outputs": [],
   "source": [
    "#to import ktrain use pip install ktrain\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "import pandas as pd\n",
    "from proj1_helpers import create_csv_submission\n",
    "from load_utils import load_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKmu08-y7hwP",
    "outputId": "ca2758e0-f1b6-414e-d1a7-a424c4f1f853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 2500000 tweets in dataframe with columns: Index(['text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#load full dataset\n",
    "tweets=load_tweets(full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "L_NIHjzBEHyY"
   },
   "outputs": [],
   "source": [
    "#create dataframe with label column 'pos' or 'neg'\n",
    "df_tweets = pd.DataFrame()\n",
    "df_tweets['label'] = tweets['label'].replace(0,'neg')\n",
    "df_tweets['label'] = df_tweets['label'].replace(1,'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBofv3kLFCTu",
    "outputId": "ad2bc746-22d1-4dab-e4fe-14124ccc5481"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500000"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify data integrity\n",
    "(df_tweets['label'] =='pos').sum() + (df_tweets['label'] =='neg').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "16Kdb_ubFWVh"
   },
   "outputs": [],
   "source": [
    "#add text column to dataframe\n",
    "df_tweets['text'] = tweets.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "tkXvA9i176Ar",
    "outputId": "87ed0898-dc87-40d2-d860-860efa7edd02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#apply bert preprocessing, we hand the label column so encoder knows how many classes there are\n",
    "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(df_tweets, 'text', 'label', \n",
    "                                                                  maxlen=30, preprocess_mode='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYR1cih6Bc05",
    "outputId": "dd87698c-cd2a-482c-b0ee-cb96bc57b7f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500000"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify data integrity\n",
    "len(y_train)+len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75kt1wWXV6FZ",
    "outputId": "b7de12a3-87d3-4d80-bd2d-06c8cc927b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 30\n",
      "done.\n",
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/3\n",
      "17579/17579 [==============================] - 8210s 467ms/step - loss: 0.2931 - accuracy: 0.8706 - val_loss: 0.2616 - val_accuracy: 0.8862\n",
      "Epoch 2/3\n",
      "17579/17579 [==============================] - 8370s 476ms/step - loss: 0.2424 - accuracy: 0.8966 - val_loss: 0.2403 - val_accuracy: 0.8976\n",
      "Epoch 3/3\n",
      "17579/17579 [==============================] - 8414s 479ms/step - loss: 0.1914 - accuracy: 0.9209 - val_loss: 0.2444 - val_accuracy: 0.8998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe8672d630>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load bert model with previously computed preprocessing\n",
    "model = text.text_classifier('bert', (x_train, y_train), preproc=preproc)\n",
    "\n",
    "# wrap model and data in ktrain.Learner object\n",
    "learner = ktrain.get_learner(model, \n",
    "                             train_data=(x_train, y_train), \n",
    "                             val_data=(x_test, y_test), \n",
    "                             batch_size=128)\n",
    "#fit 3 epochs with learning rate 2e-5\n",
    "#chosen learning rate yields reasonable results, \n",
    "#was tuned using learner.lr_find( and learner.lr_plot())\n",
    "learner.fit_onecycle(2e-5, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "m5hICB_wUlEJ"
   },
   "outputs": [],
   "source": [
    "# uncomment line below to save model and Preprocessor instance\n",
    "ktrain.get_predictor(learner.model, preproc).save('bert_predictor2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results after 3 epoch seem good, we can already see that the model starts to overfit the training data, running another epoch below confirms this trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffDw7wfusuMa",
    "outputId": "a5fa688e-e4da-4113-a7dc-4cb32ff1b6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "17579/17579 [==============================] - 8443s 480ms/step - loss: 0.1727 - accuracy: 0.9296 - val_loss: 0.2548 - val_accuracy: 0.8984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efcd1767f28>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(2e-5, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "hrs6yIhHQTb7"
   },
   "outputs": [],
   "source": [
    "#load previously saved model weights\n",
    "model1 = ktrain.load_predictor('bert_predictor2').model\n",
    "predictor1 = ktrain.get_predictor(model1, preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_mrNcOjnyyvk"
   },
   "outputs": [],
   "source": [
    "tweets= open(\"test_data.txt\").readlines()\n",
    "\n",
    "# create dataframe with positive tweets and \"1\" label\n",
    "tweets_df = pd.DataFrame()\n",
    "tweets_df['text'] = tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "6UJMihs7g4p2"
   },
   "outputs": [],
   "source": [
    "def strip_tweet(tweet):\n",
    "    comma_idx = tweet.find(',')\n",
    "    return tweet[comma_idx+1:]\n",
    "tweets_df = pd.DataFrame()\n",
    "tweets_df['text'] = [strip_tweet(t) for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "o-43uPEjy5Ih"
   },
   "outputs": [],
   "source": [
    "tweets_df['y_pred'] = tweets_df.text.apply(predictor1.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "zNzemJurFJdf"
   },
   "outputs": [],
   "source": [
    "Y_pred = tweets_df['y_pred']\n",
    "Y_pred = Y_pred.replace('pos',1)\n",
    "Y_pred = Y_pred.replace('neg',-1)\n",
    "Y_pred.index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "tt8QxW1vylPj"
   },
   "outputs": [],
   "source": [
    "create_csv_submission(Y_pred.index, Y_pred.values,\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zgq2q406aBkt",
    "outputId": "1df1403e-b14b-41c2-d8a5-ae4644543f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.91      0.89      0.90    125278\n",
      "         pos       0.89      0.91      0.90    124722\n",
      "\n",
      "    accuracy                           0.90    250000\n",
      "   macro avg       0.90      0.90      0.90    250000\n",
      "weighted avg       0.90      0.90      0.90    250000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[111649,  13629],\n",
       "       [ 11660, 113062]])"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot confusion matrix on validation set\n",
    "predictor1.analyze_valid((x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_ktrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
